{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1144a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON file\n",
    "data = []\n",
    "with open(\"data/Sarcasm_Headlines_Dataset_v2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line.strip()))  # Load each line separately\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c667f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0656d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_entities(texts):\n",
    "    person_counter = Counter()\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\"]:\n",
    "                person_counter[ent.text] += 1\n",
    "    return person_counter\n",
    "\n",
    "# Run separately on sarcastic and non-sarcastic subsets\n",
    "sarcastic_counts = extract_entities(df[df[\"is_sarcastic\"] == 1][\"headline\"].tolist())\n",
    "nonsarcastic_counts = extract_entities(df[df[\"is_sarcastic\"] == 0][\"headline\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94a8b67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('u.s.', 212), ('white house', 100), ('bush', 98), ('clinton', 84), ('congress', 68), ('gop', 61), ('america', 58), ('senate', 47), ('god', 43), ('obama', 42)]\n",
      "[('donald trump', 285), ('u.s.', 231), ('gop', 209), ('america', 158), ('hillary clinton', 133), ('trump', 102), (\"donald trump's\", 96), ('senate', 84), ('california', 76), ('congress', 70)]\n"
     ]
    }
   ],
   "source": [
    "print(sarcastic_counts.most_common(10))\n",
    "print(nonsarcastic_counts.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fddf18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5446f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())  # Should print True if CUDA is enabled\n",
    "print(torch.version.cuda) \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"charaydes/deberta-v3-large-finetuned-sarcasm\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"charaydes/deberta-v3-large-finetuned-sarcasm\").to(\"cuda\") \n",
    "\n",
    "bush = \"bush makes last-minute push to appeal to whites\"\n",
    "donald_trump = \"donald trump makes last-minute push to appeal to whites\"\n",
    "headlines = [bush, donald_trump]\n",
    "\n",
    "inputs = tokenizer(headlines, padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "batch_size = 16\n",
    "dataset = TensorDataset(inputs[\"input_ids\"], inputs[\"attention_mask\"])\n",
    "loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "all_preds = []\n",
    "torch.cuda.empty_cache()\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        input_ids, attention_mask = [x.to(\"cuda\") for x in batch]\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "\n",
    "print(all_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
